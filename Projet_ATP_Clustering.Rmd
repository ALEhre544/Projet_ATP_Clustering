---
documentclass: "compterendu"
lang: true
babel-lang: "french"
geometry:
  - left=1.5cm
  - right=1.5cm
  - top=1.5cm
  - bottom=2cm
title: "Clustering sur les joueurs ATP de l'année 2012."
author: 
  - EHRE
  - ABBASSI
  - BOUR
  - SANTOU
  - GNANASEELAN-BENEDICT
  - HOUNKPATIN
email:
  - Alicia
  - Mehdi
  - Léon
  - Emmanuel
  - Jathurshan
  - Cadnel
date: "`r format(Sys.time(), '%d %B %Y')`"
abstract: "Réalisation d'un clustering sur les joueurs ATP de l'année 2012."
anac: "2020-2021"
diplome: "Master 2 - Statistiques pour l'Evaluation et la Prévision"
module: "SEP0922"
enseig: "Philippe Regnault"
evaluation: "Clustering"
output: 
  bookdown::pdf_book:
    template: template.tex
    fig_caption: yes
    keep_tex: yes
    toc: yes
bibliography: biblio_cr-urca.bib
biblio-style: plain
link-citations: yes
---

```{r, include = FALSE}

library(tidyverse)
library(factoextra)
library(FactoMineR)
library(NbClust)
library(dendextend)
library(fpc)
library(devtools)
library(kableExtra)
#install_github("larmarange/JLutils")

```

```{r, include = FALSE}

#Ce bloc configure quelques options d'affichage pour les blocs R
library('knitr')
opts_chunk$set(comment = '', echo = FALSE,  tidy = TRUE, 
               fig.pos = 'ht!', fig.align='center', fig.width= 4.5, fig.height = 3.2)

```

```{r, include = FALSE}

players <- read_csv("tennis_atp/atp_players.csv", col_names = FALSE)
names(players) <- c("id", "firstname", "lastname", "hand", "birthday", "nat")

df <- read_csv("tennis_atp/atp_matches_2012.csv")

```

```{r, include = FALSE}

# Créer un tableau agrégé des gagnants
df_winner <- df  %>%
  group_by(winner_name) %>%
  summarise(w_ace = mean(w_ace, na.rm = TRUE),
            w_ht = winner_ht,
            w_age= round(winner_age),
            w_stIn = mean(w_1stIn, na.rm = TRUE),
            w_stWon = mean(w_1stWon, na.rm = TRUE),
            w_svpt = mean(w_svpt, na.rm = TRUE),
            w_svgms = mean(w_SvGms, na.rm = TRUE),
            w_bpSaved = mean(w_bpSaved, na.rm = TRUE),
            w_bpFaced = mean(w_bpFaced, na.rm = TRUE),
            w_min = mean(minutes, na.rm = TRUE))
df_winner <- distinct(df_winner,.keep_all = TRUE)

# Créer un tableau agrégé des perdants
df_loser <- df  %>%
  group_by(loser_name) %>%
  summarise(l_ace = mean(l_ace, na.rm = TRUE),
            l_ht = loser_ht, 
            l_age= round(loser_age),
            l_stIn = mean(l_1stIn, na.rm = TRUE),
            l_stWon = mean(l_1stWon, na.rm = TRUE),
            l_svpt = mean(l_svpt, na.rm = TRUE),
            l_svgms = mean(l_SvGms, na.rm = TRUE),
            l_bpSaved = mean(l_bpSaved, na.rm = TRUE),
            l_bpFaced = mean(l_bpFaced, na.rm = TRUE),
            l_min = mean(minutes, na.rm = TRUE))
df_loser <- distinct(df_loser,.keep_all = TRUE)


# Donner le même nom du variable au "winner_name" et "loser_name"  
df_loser <- rename(df_loser, player = loser_name )
df_winner <- rename(df_winner, player = winner_name)

# Jointure des tables
df_player <- full_join(df_winner, df_loser, by = "player")

# Combinaison des variables
df_player <- mutate(df_player, ace = w_ace + l_ace,
                    height = case_when(w_ht == l_ht ~ w_ht, w_ht != l_ht ~ l_ht),
                    age = round(max(w_age,l_age)),
                    stin = w_stIn  + l_stIn,
                    stWon = w_stWon + l_stWon,
                    svpt = w_svpt +l_svpt,
                    svgms = w_svgms + l_svgms,
                    bpSaved = w_bpSaved + l_bpSaved,
                    bpFaced = w_bpFaced + l_bpFaced,
                    min = l_min + w_min) %>%
  select(ace, height, age, stin, stWon, svpt, svgms, bpSaved, bpFaced, min)

# Supprimer les valeurs manquantes
df_player <- distinct(df_player,.keep_all = TRUE)
df_player %>%
  select(ace, height, stin, stWon, svgms, bpSaved, bpFaced, min) %>%
  drop_na() -> df_clean
df_clean <- as.data.frame(df_clean)
rownames(df_clean) <- df_clean[,1]
df_clean <- df_clean[,-1]

```


# Contextualisation

  Au tennis il existe différents styles de jeu : les défenseurs, les attaquants de fond de court, les contreurs, les joueurs complets et les attaquants de type service volée. Il ne faut pas oublier que chaque joueur est différent pour un même style de jeu. En effet, la tactique pourra être différente en fonction de l'adversaire et en fonction de l'état physique et psychologique du joueur.

Notre objectif est de déterminer différents profils de joueurs selon leur type de jeu en se basant sur l'année 2012 des résultats des matchs ATP.


## Choix des variables

  Nos bases de données correspondent aux résultats des matchs de tennis des circuits professionnels ATP téléchargeables depuis les dépôts GitHub de Jeff Sackmann. L’objectif est de rendre compte du plus large aspect possible en terme de jeu pratiqué. Au total, ce sont 8 variables explicatives numériques qui ont été sélectionnées :

* minutes : La durée du match
* l/w_ace : Nombre des services gagnants par match
* l/w_df : Nombre de services gagnés par doubles fautes de l'adversaire (par match)
* l/w_svpt : Nombre de service servi (par match)
* l/w_1stIn : Nombre de services réussis du premier coup
* l/w_2ndWon : Nombre de fois où le joueur a gagné le premier point dès le deuxième service
* l/w_SvGms : Nombre de parties où le joueur a serv
* l/w_bpSaved : Nombre de points de break sauvé
* l/w_bpFaced : Nombre de points de break rencontrés
* loser/winner_ht : La taille du joueur

# Clustering

  Nous souhaitons faire un clustering pour séparer les joueurs ATP de l'année 2012 en différents groupes de joueurs caractérisés principalement par le style de jeu des joueurs.

## Choix du partitionnement

  Pour réaliser ce clustering nous avons comparé les résultats des méthodes Kmeans et de classification ascendante hiérarchique (CAH). Dans un premier temps, il faut trouver le nombre de clusters optimal. Pour la méthode des kmeans nous avons utilisé la fonction nbclust du package NbClust, nous donnant le nombre optimal de clusters pour la méthode des kmeans avec comme distance choisie la distance euclidienne.

```{r, include = FALSE}

set.seed(123)
df_kmeans <- as.data.frame(scale(df_clean, center=T, scale=T))
nb <- NbClust(df_kmeans, distance = "euclidean", min.nc = 2, max.nc = 10, method = "kmeans")
#fviz_nbclust(nb) 
#Trouver comment prendre que le dernier graph

```

L'ensemble des critères de recherche du nombre optimal de clusters pour la CAH propose un nombre optimal de clusters de 3. Cependant, pour être sûr de trouver le meilleur partitionnement, nous allons comparer la CAH à 3 clusters avec la CAH à 4 clusters.


```{r tab1, echo = FALSE, eval = TRUE}

`Méthode`= c("ward.D","single","complete","average","mcquitty","median","centroid","ward.D2")
`Nombre de clusters`=  c("3","3","3","3","3","3","3","3")
tab <- cbind(`Méthode`,`Nombre de clusters`)
kable(tab, caption="(ref:tab1)") %>%
  kable_styling(position="center", latex_options= c("striped", "HOLD_position"))

```

(ref:tab1) Nombre de clusters optimal pour la méthode de CAH selon les critères.

### Comparaison des coefficients de silhouette

  Dans un premier temps nous allons comparer les coefficients de silhouette des différents partitionnements.

```{r, echo = FALSE, eval = TRUE}

set.seed(123)
km <- kmeans(df_kmeans, 4)
df_clean$classe_km <- km$cluster
# Coefficients de silhouette
#si <- cluster::silhouette(km$cluster,dist(df_kmeans,"euclidean"))
#plot(si)
#factoextra::fviz_silhouette(si) + ggplot2::ylim(-1,1) 
#trouver comment prendre que le graph et pas les affichages console

```


```{r tab2, echo = FALSE, eval = TRUE}

`Cluster`= c("1","2","3","4")
`Nombre d'individus`=  c("24","14","47","102")
`Coefficients de silhouette moyens`=  c("0,29","0,18","0,28","0,18")
tab <- cbind(`Cluster`,`Nombre d'individus`,`Coefficients de silhouette moyens`)
kable(tab, caption="(ref:tab4)") %>%
  kable_styling(position="center", latex_options= c("striped", "HOLD_position"))

```

(ref:tab2) Coefficients de silhouette moyens avec la méthode des Kmeans à 4 clusters.


```{r, echo = FALSE, eval = TRUE, message = FALSE}

df_CAH <- as.data.frame(scale(df_clean, center=T, scale=T))
D_cah <- dist(df_CAH,"euclidean")
CAH <- hclust(D_cah, method = "ward.D2")

# Comparaison 3 - 4 clusters avec CAH
clu_3 <- cutree(CAH,3)
clu_4 <- cutree(CAH,4)
si_cah_3 <- cluster::silhouette(clu_3, D_cah)
si_cah_4 <- cluster::silhouette(clu_4, D_cah)
df_CAH$classe <- clu_4
df_clean$classe_hc <- df_CAH$classe
plot(si_cah_3)
plot(si_cah_4)
# s3 <- factoextra::fviz_silhouette(si_cah_3) + ggplot2::ylim(-1,1)
# s4 <- factoextra::fviz_silhouette(si_cah_4) + ggplot2::ylim(-1,1)
# gridExtra::grid.arrange(s3,s4, ncol = 2, nrow = 1)
# trouver comment prendre que le graph et pas les affichages console


```

```{r tab3, echo = FALSE, eval = TRUE}

`Cluster`= c("1","2","3")
`Nombre d'individus`=  c("24","14","149")
`Coefficients de silhouette moyens`=  c("0,49","0,31","0,44")
tab <- cbind(`Cluster`,`Nombre d'individus`,`Coefficients de silhouette moyens`)
kable(tab, caption="(ref:tab3)") %>%
  kable_styling(position="center", latex_options= c("striped", "HOLD_position"))

```

(ref:tab3) Coefficients de silhouette moyens avec la méthode CAH à 3 clusters.


```{r tab4, echo = FALSE, eval = TRUE}

`Cluster`= c("1","2","3","4")
`Nombre d'individus`=  c("24","14","47","102")
`Coefficients de silhouette moyens`=  c("0,46","0,28","0,29","0,38")
tab <- cbind(`Cluster`,`Nombre d'individus`,`Coefficients de silhouette moyens`)
kable(tab, caption="(ref:tab4)") %>%
  kable_styling(position="center", latex_options= c("striped", "HOLD_position"))

```

(ref:tab4) Coefficients de silhouette moyens avec la méthode CAH à 4 clusters.

Les coefficients de silhouette sont meilleurs avec la méthode de la CAH plutôt qu'avec les Kmeans. De plus, à l'aide de la fonction cluster_similarity du package clusteval, les indice de Jaccard (égal à 1 ici) et de Rand (1 également) nous montre qu'un kmeans à 4 clusters nous donne la même partition qu'une CAH à 4 clusters. Le choix se fait donc entre une CAH à 3 ou 4 clusters. Pour faire ce choix il faut comparer les inerties des classifications. 

### Comparaison des inerties

Pour avoir un bon partitionnement il nous faut minimiser son inertie intraclasse et maximiser son inertie interclassse. C'est pourquoi, nous comparons maintenant les inerties intra et interclasse des partitionnement par CAH à 3 clusters et par CAH à 4 clusters.

```{r, include = FALSE}

#Les fonctions d'inertie

inertie_cor<-function(df,p=NULL){
  if (is.null(p)){ p <- rep(1,nrow(df))}
  g <- ( p %*% as.matrix(df) ) / sum(p)
  iner <- 0
  for (i in seq(nrow(df))){ iner <- iner + sum((df[i,] - g)^2) * p[i]   }
  return(iner)
}

inertie_inter_cor<-function(df,lab){
  M<-matrix(rep(0,ncol(df)*length(unique(lab))),ncol = ncol(df))
  for (k in unique(lab)){
    M[k,]<-unname(colMeans(df[which(lab==k),]))
  }
  return(inertie_cor(data.frame(M),unname(table(lab))))
}

inertie_intra_cor <- function(df,lab){
  res <- rep(0,length(unique(lab)))
  for (i in unique(lab)) {
    res[i] <- inertie_cor(df[which(lab==i),])
  }
  return(sum(res))
}

```


```{r tab5, echo = FALSE, eval = TRUE}

`CAH`= c("Intertie interclasse","Intertie interclasse")
`3 clusters`=  c("976,72","900,72")
`4 clusters`=  c("704,78","1172,67")
tab <- cbind(`CAH`,`3 clusters`,`4 clusters`)
kable(tab, caption="(ref:tab5)") %>%
  kable_styling(position="center", latex_options= c("striped", "HOLD_position"))

```

(ref:tab5) Inertie intra et interclasse par la méthode de CAH à 3 et 4 clusters.

La CAH à 4 clusters minimise le mieux l'inertie intraclasse et maximise le mieux l'inertie interclasse, en comparaison avec la CAH à 3 clusters et ce phénomène a été vérifié en comparant avec les résultats des Kmeans. Ainsi la méthode sélectionnée est la méthode des CAH à l'aide du critère de ward avec 4 clusters. 

(ref:clust) Clustering par la méthode de CAH avec la distance euclidienne et le critère de ward.

```{r clust, fig.cap="(ref:clust)", echo = FALSE, eval = TRUE}

factoextra::fviz_cluster(list(data=df_CAH, cluster=clu_4),geom="point", data = df_CAH, main='')

```

## Les clusters - Interprétation

  Nous allons donc maintenant étudier nos 4 clusters obtenus à l'aide de la méthode de CAH, afin de voir comment ils se distinguent les uns des autres, et voir quel style de jeu peut correspondre à chacun d’entre eux. Il serait intéressant de voir si jamais certains groupes sont « complémentaires » avec d’autres (au niveau des valeurs prises par les indicateurs statistiques), ainsi que d’observer la répartition des plus grands joueurs de tennis parmi ces groupes.


  Le premier cluster se démarque des autres sur plusieurs points. Tout d'abord, le groupe se caractérise par 3/4 des joueurs avec une taille en dessous de la moyenne (1m85) et un nombre d'ace réalisé inférieur à la moyenne pour plus des 3/4 des joueurs (Annexe 1). De plus, les 24 joueurs de ce premier cluster réalise moins de service que les autres clusters, mais ont un pourcentage de services réussis du premier coup équivalent à celui des autres clusters (environ 60%). Cependant leur performance au niveau des points marqués lors du premier échange est beaucoup plus faible que pour les autres clusters (Annexe 2). De même, ils ont un plus faible taux de break points sauvés et rencontrés que pour les autres clusters. En effet, ils ne sauvent en moyenne que 51% des break points rencontrés tandis que la moyenne est au minimum de 60% dans les autres clusters (Annexe 3). Enfin, ce cluster est composé de joueurs jouant des matchs beaucoup plus courts en moyenne que pour les joueurs des autres clusters (Annexe 4). Cela pourrait s'expliquer par le fait de ne pas jouer de grand chelems. 

Ainsi ce groupe serait composé des joueurs plutôt de petite taille, n'ayant pas un service puissant et/ou une attaque puissante. De plus, ils joueraient des matchs plus courts en moyenne, ce qui pourrait provennir du fait qu'ils ne jouent pas ou peu de grands chelems. Tout ceci pourrait avoir un lien avec le fait que ce cluster est caractérisé par des joueurs plutôt jeunes. En effet, 50% des joueurs ont moins de 26 ans et 75% moins de 28 ans, alors que l'age moyen de l'ensemble des joueurs ATP de 2012 est de 27 ans. Les joueurs de ce cluster sont donc en général plus jeunes que la moyenne et auraient donc moins d'expériences.




  Le deuxième cluster est composé de 14 joueurs. La taille moyenne des joueurs de ce cluster varie entre 1m73 et 1m90 avec une moyenne de 1m84. Ces joueurs sont rélativement grands par rapport aux groupes 1 et 4 (Annexe 1).
De plus, les joueurs réussissent en moyenne 61% de leurs services du premier coup, ce qui est équivalent aux autres clusters. Cependant, ce groupe se positionne à la tête des clusters en terme de gain du premier point dès le premier échange, les joueurs de ce cluster s'illustrent donc mieux avec une moyenne environ de 85 par match ce qui est considérablement supérieur aux moyennes des autres clusters. De même, ils réalisent 11% de ace parmis leurs services réussis, ce qui est le deuxième meilleur taux parmis nos clusters. Enfin, dans la catégorie des points de break sauvés ce cluster fait encore la différence avec 63% de break sauvés en moyenne par match ce qui est supérieur aux moyennes des autres clusters.

En définitive, les joueurs de ce cluster ont une taille moyenne et ont l'avantage au niveau des points de break sauvés. De plus, ils ont la capacité de gagner rapidement des points dès le premier échange, ce qui justifie leur reussite. Ils réalisent donc d'énormes performances au niveau du nombre de points gagnés dès le premier échange. On a donc des joueurs qui sont très bons en service et gagnent d'importantes balles de matchs. 

### Cluster 3

A FAIRE

### Cluster 4

```{r, include = FALSE}
df_clean %>% filter(classe_hc == 4) -> Base4
Base4 <- Base4[,-c(9,10)]
```

Le quatrième cluster contient `r round(nrow(Base4)/nrow(df_clean)*100,2)`% observations. Les joueurs les plus connus, dans ce cluster sont notamment Nadal et Wavrinka. Les joueurs qui composent ce groupe, ont en moyenne 27 ans. Pour la plus part ils sont donc expérimenté dans ce sport. Les joueurs font en moyen `r round(mean(Base4$height),2)` cm. En moyenne, les joueurs de ce groupe sont plus petit que les joueurs des autres clusters.

De plus, tous les joueurs de ce groupe sont généralement bons en service. En effet, ils réussisent en genéral plus de 61% de leurs services du premier coup, c'est le meilleur taux de nos clusters (Annexe 3). Par ailleurs, ces joueurs sont très forts sur les balles de break car lorsqu'ils ont à faire face a une balle de break, 60% du temps ils arrivent à la sauver. Le graphique (Annexe 5) permet de montrer la corrélation entre le nombre de breaks auquel les joueurs font faces et le nombre de breaks qu'ils ont sauvés ainsi on aperçoit clairement que lorsque le nombre de balles de break auquel ils font face augmente, il est plus probable que ces derniers arrive à les sauver. Enfin, ce groupe joue en moyenne 3h41, ceci s'explique par la présence de grands joueurs tels que:
Nadal, Monfils, Lewitt ou encore Wavrinka. Ces joueurs participent au grands chelems qui se jouent sur 3 sets et non 2. Ainsi cela explique qu'ils jouent plus que la moyenne.
La présene d'Hernych et  Denis Gremelmayr sont a douter. En effet, Ces 2 joueurs ne correspondent pas aux critères cités plus haut (Annexe 6). Ils doivent probablement jouer avec un autre style de jeu.

# Conclusion

A FAIRE 

# (APPENDIX) Annexes {-}

## Annexe 1 : Comparaison du taux d'aces réalisés et de la taille des joueurs dans les différents clusters.


(ref:ace) Répartition du nombre de aces et de la taille des joueurs au sein des clusters

```{r ace, fig.cap="(ref:ace)", echo = FALSE, eval = TRUE}

df_clean %>% 
  ggplot() + 
  geom_boxplot(mapping = aes(x = as.character(classe_hc), y = ace, fill = as.character(classe_hc) )) +
  labs(fill = 'Clusters', y = 'Nombre moyen de aces', x = '') -> g_age

df_clean %>% 
  ggplot() + 
  geom_boxplot(mapping = aes(x = as.character(classe_hc), y = height, fill = as.character(classe_hc) )) +
  labs(fill = 'Clusters', y = 'Taille (en cm)', x = '') -> g_height

gridExtra::grid.arrange(g_age, g_height, ncol = 2, nrow = 1)

```

Le taux de ace par clusters semble très différent. En effet, les joueurs du cluster 1 ont un taux de ace plus faible que la moyenne (score de 11) pour la quasi totalité des joueurs. Les joueurs du cluster 4 sont quand à eux 75% à avoir un taux plus faible que la moyenne. Concernant le cluster 2 les résultats s'améliorent avec plus de 25% des joueurs ayant un taux de ace au dessus de la moyenne. Enfin le cluster 3 se démarque par la quasi-totalité de ses joueurs ayant un taux de ace au dessus de la moyenne. En prenant le pourcentage de ace par rapport au nombre de services réussis, ce phénomène se confirme. En effet, le cluster 3 se démarque avec en moyenne 18% de ace parmis leurs services réussis. Les clusters 1, 4 et 2 se retrouvent avec respectivement 8,8% , 9% et presque 11%. On retrouve bien les clusters 1 et 4 avec le moins de aces réalisés et le cluster 2 avec des meilleurs performances mais encore loin de celles du cluster 3.


```{r tab6, echo = FALSE, eval = TRUE}

`Cluster`= c("1","2","3","4")
`Pourcentage moyen de ace`=  c("8,76","10,84","18,55","9,07")
tab <- cbind(`Cluster`,`Pourcentage moyen de ace`)
kable(tab, caption="(ref:tab6)") %>%
  kable_styling(position="center", latex_options= c("striped", "HOLD_position"))

```

(ref:tab6) Pourcentage moyen de ace par clusters.

Il y a un phénomène similaire concernant la taille des joueurs au sein des clusters. En effet, le cluster 1 et 4 ayant les moins bon taux de ace ont également les joueurs les plus petits, 75% de leurs joueurs sont plus petits que la moyenne des joueurs ATP de 2012 qui est de 1m85. Les joueurs du cluster 2 ont une taille plutôt bien répartie autour de la moyenne. Enfin, le cluster 3 se démarque par des joueurs de grandes tailles, la quasi totalité des joueurs ont une taille supérieur à la moyenne de 1m85.

On remarque donc une forte corrélation entre le fait d'être de grande taille et d'avoir une meilleure performance dans la réalisation de ace.

## Annexe 2 : Rapport brek points sauvés/rencontrés pour chaque cluster

```{r tab7, echo = FALSE, eval = TRUE}

`Cluster`= c("1","2","3","4")
`Pourcentage moyen de points de break sauvés`=  c("51,15","63,54","63,01","59,69")
tab <- cbind(`Cluster`,`Pourcentage moyen de points de break sauvés`)
kable(tab, caption="(ref:tab7)") %>%
  kable_styling(position="center", latex_options= c("striped", "HOLD_position"))

```

(ref:tab7) Pourcentage moyen de points de break sauvés par clusters.

Lorsque l'on regarde le pourcentage moyen de break points sauvés on remarque que les joueurs du cluster 1 ne sauvent que 51% des breaks, tandis que pour les autres clusters ce pourcentage est au minimum de 60%. En particulier les les joueurs du clusters 2 et 3 ont des pourcentages de réussite d'environ 63%.

## Annexe 3 : Comparaison des services réussis pour chaque cluster

(ref:stin) Répartition du nombre moyen de services réussis au sein des clusters

```{r stin, fig.cap="(ref:stin)", echo = FALSE, eval = TRUE}

df_clean %>% 
  ggplot() + 
  geom_boxplot(mapping = aes(x = as.character(classe_hc), y = stin, fill = as.character(classe_hc) )) +
  labs(y = 'Nombre moyen de services réussis', x = '',fill ='Clusters')

```

Le taux de services réussis du premier coup semble hétérogènes selon les clusters. En effet, les joueurs du cluster 2 semblent se détacher avec de meilleures performance. A l'opposé les joueurs du cluster 1 semblent avoir de moins bonnes performances, plus de difficultés à réussir leur service du premier coup. Cependant, lorsque l'on regarde le taux de services réussis en fonction du nombre de services faits, on observe que dans tous les clusters le pourcentage moyen de services réussis du premier coup est d'environ 60%. Le taux de services réussis du premier coup n'est donc pas un critère déterminant pour différencier les différents clusters.


```{r tab8, echo = FALSE, eval = TRUE}

`Cluster`= c("1","2","3","4")
`Pourcentage de services réussis du premier coup`=  c("59,43","60,93","61,34","60,89")
tab <- cbind(`Cluster`,`Pourcentage de services réussis du premier coup`)
kable(tab, caption="(ref:tab8)") %>%
  kable_styling(position="center", latex_options= c("striped", "HOLD_position"))

```

(ref:tab8) Pourcentage de services réussis du premier coup par clusters.


## Annexe 4 : Comparaison de la durée moyenne des matchs dans les différents clusters.

(ref:min) Répartition de la durée moyenne des matchs au sein des clusters

```{r min, fig.cap="(ref:min)", echo = FALSE, eval = TRUE}

df_clean %>% 
  ggplot() + 
  geom_boxplot(mapping = aes(x = as.character(classe_hc), y = min, fill = as.character(classe_hc) )) +
  labs(y = 'Durée moyenne des matchs (minutes)', x = '', fill ='Clusters')

```

La durée moyenne des matchs varient en fonction des clusters. En effet, le cluster 1 a une durée des matchs nettement inférieure à la durée moyenne de 1h45. Tandis que les joueurs des clusters 3 et 4 ont joués des matchs avec une durée aux alentours de la durée moyenne. Enfin, les joueurs du cluster 2 ont une tendance à jouer des matchs nettement plus longs que la moyenne. 
Ce phénomène pourrait s'expliquer par le nombre de matchs joués en grands chelems par les joueurs des différents clusters.

## Annexe 5 : Corrélation entre le nombre de breaks sauvés et le nombre de breaks affrontés.


(ref:BP) Corrélation entre les balles de break sauvées et rencontrées.

```{r BP, fig.cap="(ref:BP)", echo = FALSE, eval = TRUE}

ggplot(data = Base4 ,mapping = aes(x = bpFaced, y = bpSaved)) +
  geom_point() +
  geom_smooth(method="lm") +
  labs(y = 'Points de break sauvés', x = 'Points de break rencontrés')

```

## Annexe 6: ACP pour le cluster 4

(ref:acp) ACP du cluster 4

```{r acp, fig.cap="(ref:acp)", echo = FALSE, eval = TRUE}

acp <- FactoMineR::PCA(Base4,scale.unit = T,graph=FALSE)
fviz_pca(acp)

```
L'ACP permet de confirmer que les deux joueurs cités plus haut ne font pas partie du bon groupe. En effet, ces derniers peuvent être considerés comme des individus suplémentaires. Par ailleurs, la contribution de chacun s'élève à 0.0194 et 0.0549, ceux qui est très faible.
